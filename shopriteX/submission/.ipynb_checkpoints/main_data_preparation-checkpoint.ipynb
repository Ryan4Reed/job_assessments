{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d066d37",
   "metadata": {},
   "source": [
    "# Main Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066ac6e",
   "metadata": {},
   "source": [
    "This notebook is dedicated to the initial/main data preparation for the prediction task at hand. Some important steps completed are as follows:\n",
    "\n",
    "\n",
    "* __Aggregate data to a monthly level__\n",
    "    * Explanation: As illustrated in the xgboost_daily notebook, I completed an initial forecast on a daily level. After investigating the results it became clear that because of the zero inflated nature of the daily training data, any prediction algorith would struggle to do better than just predicting the majortiy class (no sales). As a result, and still inline with the requested assignment, I decided to aggregate sales to a monthly level in order to create a more balanced dataset.\n",
    "</br>\n",
    "</br>\n",
    "* __Limit the data to products sold in 2020__\n",
    "    * Explanation: In order to cleanup the data and reduce the amount of data we need to work with in order to satisfy memory constraints, I limit the data to only include products that were sold in 2020. The logic behind this reduction is that products that have not been sold in the first 5 months of 2020 do not require forecasting. Their forecast is simply 0.\n",
    "</br>\n",
    "</br>\n",
    "* __Limit the dataset to the past 15 months__\n",
    "    * Explanation: The motivation for excluding data prior to 2019-03-01 was twofold. \n",
    "        * First, it is a question of relevance. How relevant is the sales of a product 2 years prior to the sales of the product today (especially compared to the relevance of more recent sales)? As such, the first motivation to exclude this data was to aid the ml model to focus on more recent data points. \n",
    "        * The second motivation was again one of memory limitation (to reduce data size). \n",
    "</br>\n",
    "</br>\n",
    "* __Add entries for days on which a product was not sold__\n",
    "    * Explanation: The received dataset contained entries for each product only on days for which it was sold. The zero sale days for each product-shop combination is missing, and very relevant information for properly training a forecasting model. In constructing these mising data points, the following assumption was addopted:\n",
    "        * On a day that a product was not sold it is assumed that the price was as on its previous sell date. If this is not available, it is set equal to its next sell price instance\n",
    "</br>\n",
    "</br>\n",
    "* __Separate data by shop__\n",
    "    * Explanation: The received dataset contained information related to 59 different shops. I made the decision to separate the data wrt each shop and create a separate forecasting model for each. The motivation for doing so was both wrt aiding the prediction model to better map the sales function wrt each shop, and the fact that the underlying patterns that drive sales at different shops are most likely unique (if the region in which a shop is located is different from the next shop, we cannot bundle the prediction task, thereby assuming that shops are essentially homogenous). A motivation to bundle the shops into a single prediction model would be if the sales at the shops are not independ (as I have assumed). This would be the case if, for example, the shops are all serviced by a central depo that runs out of stock. Resulting in an interdepence between sales across shops.\n",
    "</br>\n",
    "</br>\n",
    "* __An assumption to note__\n",
    "    * Explanation: It was assumed that all the products at a shop were sold at least once. In this way, products that do now show up wrt a shop in the received data are assumed not to be stocked there and thus do not require predicting. \n",
    "\n",
    "    \n",
    "__Instructions for executing__: Just run cells from top to bottom. The last cell contains a main function that facilitates the execution of all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f6df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e2f9d",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0ac8c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import data\n",
    "def create_main_df(sales_path: str, items_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create the main dataframe containing the raw sales data.\n",
    "    :param sales_path: String pointing to sales file\n",
    "    :param items_path: Sting pointing to items file\n",
    "    :return: pd.DataFrame containg sales data merged with item category data\n",
    "    \"\"\"\n",
    "    #Load csv with sales data\n",
    "    df_sales = pd.read_csv(sales_path)\n",
    "    #Load cvs with product category data\n",
    "    df_items = pd.read_csv(items_path)\n",
    "    #Merge\n",
    "    df = pd.merge(df_sales, df_items, on='item_id')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf8c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate data\n",
    "def construct_monthly_sales_df(df_func: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate sales data to monthly.\n",
    "    :param df_func: pd.DataFrame containing the sales data current on a daily level\n",
    "    :return: pd.DataFrame containing aggregated sales data\n",
    "    \"\"\"\n",
    "    #Create column on which to group data\n",
    "    df_func['year_month'] = df_func.apply(lambda row:  str(row['year']) + str(row['month']), axis=1)\n",
    "    #Construct monthly dataframe\n",
    "    df_func = df_func.groupby(by=['year_month', 'shop_id', 'item_id', 'item_category_id']).agg({'item_cnt_day': 'sum', 'item_price': 'mean'}).reset_index()\n",
    "    #Rename columns\n",
    "    df_func.rename(columns={'item_cnt_day': 'item_count_month'}, inplace=True)\n",
    "    #Round item price\n",
    "    df_func['item_price'] = df_func['item_price'].round(1)\n",
    "    #Recreate year and month columns\n",
    "    df_func['year'] = df_func['year_month'].apply(lambda x:  int(x[:4]))\n",
    "    df_func['month'] = df_func['year_month'].apply(lambda x:  int(x[4:]))\n",
    "    #Assign day equal to 1 as placeholder\n",
    "    df_func['day'] = 1\n",
    "    #Generate datetime\n",
    "    df_func['date'] = pd.to_datetime(df_func[['year', 'month', 'day']])\n",
    "    \n",
    "    return df_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82be63da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#limit the data set to products that sold in 2020\n",
    "def twenty20_products(df_func: pd.DataFrame, date_limit: datetime) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Limit data to product that were sold in 2020.\n",
    "    :param df_func: pd.DataFrame containing sales data\n",
    "    :param date_limit: datetime object indicating relevant cutoff date\n",
    "    return: pd.DataFrame containing filtered products\n",
    "    \"\"\"\n",
    "    #Identify products\n",
    "    prods_sold_2020 = df_func[df_func['date']>= date_limit]['item_id'].unique()\n",
    "    #Limit dataframe\n",
    "    df_func = df_func.drop(df_func[~df_func['item_id'].isin(prods_sold_2020)].index)\n",
    "    \n",
    "    return df_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecdeb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit the data set to the past 15 months\n",
    "def limit_data_by_date(df_func: pd.DataFrame, date_limit: datetime) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Limit data to sales after date_limit.\n",
    "    :param df_func: pd.DataFrame containing sales data\n",
    "    :param date_limit: datetime object indicating relevant cutoff date\n",
    "    return: pd.DataFrame containing filtered products\n",
    "    \"\"\"\n",
    "    df_func = df_func.drop(df_func[df_func['date']< date_limit].index)\n",
    "    \n",
    "    return df_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "890fab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unwanted columns\n",
    "def drop_columns(df_func: pd.DataFrame, \n",
    "                 columns_to_drop: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove the columns we do not want to include in the saved data.\n",
    "    :param df_func: pd.DataFrame containing sales data\n",
    "    :param columns_to_drop: List containing columns to remove from df\n",
    "    :return: pd.DataFrame containg filtered columns\n",
    "    \"\"\"\n",
    "    df_func = df_func.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "    return df_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67143f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add entries for days on which a product was not sold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_item_price(df_func: pd.DataFrame, date: datetime) -> int:\n",
    "    \"\"\"\n",
    "    Determine the price of a product wrt a day on which there were no sales for it.\n",
    "    #ASSUMPTION MADE: On a day that a product was not sold it is assumed that the \n",
    "    price was as on its previous sell date. If this is not available, it is set \n",
    "    equal to its next sell price instance\n",
    "    :param df_func: pd.DataFrame containing sales data\n",
    "    :param date: datetime object indicating date of interest\n",
    "    :return: Integer specifying price\n",
    "    \"\"\"\n",
    "    price_list_before = df_func[df_func.index <= date]['item_price'].unique()\n",
    "    price_list_after = df_func[df_func.index > date]['item_price'].unique()   \n",
    "    if len(price_list_before) > 0:\n",
    "        return price_list_before[-1]\n",
    "    else: \n",
    "        return price_list_after[0]\n",
    "    \n",
    "def get_item_category(df_func: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Retrieve the category to which a particular product belongs.\n",
    "    :param df_func: pd.DataFrame containg sales data\n",
    "    :return: Integer specifying product category\n",
    "    \"\"\"\n",
    "    category = df_func['item_category_id'].unique()[0]\n",
    "    return category\n",
    "\n",
    "def add_no_sale_entries(df_func: pd.DataFrame, \n",
    "                        months: pd.Series,\n",
    "                       unique_shops: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each product-shop combination, add an entry for days on which there were no sales.\n",
    "    :param df_func: pd.DataFrame containing sales data\n",
    "    :param months: pd.Series indicating months of interest\n",
    "    :param unique_shops: List of all shop ids\n",
    "    :return: Ammended pd.DataFrame now containing zero entries for no sale days\n",
    "    \"\"\"\n",
    "    #TODO: Optimise code further\n",
    "    for shop in unique_shops:\n",
    "        print(shop)\n",
    "        df_shop = df_func[df_func['shop_id'] == shop]\n",
    "        for i, prod in enumerate(df_shop['item_id'].unique().tolist()):\n",
    "            df_prod = df_shop[df_shop['item_id']==prod]\n",
    "            #Determine months with no sales\n",
    "            months_sold = df_prod.index.tolist()\n",
    "            months_not_sold = list(set(months) ^ set(months_sold))\n",
    "            rows_to_add = []\n",
    "            indexs = []\n",
    "            for month in months_not_sold:\n",
    "                #Create entry\n",
    "                item_price = get_item_price(df_func, month)\n",
    "                item_category = get_item_category(df_func)\n",
    "                sold=0\n",
    "                new_row = {'shop_id': shop, 'item_id':prod, 'item_category_id':item_category, 'item_count_month':sold, 'item_price':round(item_price, 1), 'year':month.year, 'month':month.month}\n",
    "                rows_to_add.append(new_row)\n",
    "                indexs.append(month)\n",
    "            #Append created entry to df\n",
    "            df_shop  = df_shop.append(pd.DataFrame(rows_to_add,index=indexs,columns=df_shop.columns))\n",
    "        #Sort df by date\n",
    "        df_shop = df_shop.sort_index(ascending=True)\n",
    "        #Write df to file\n",
    "        df_shop.to_csv('aug_monthed_data_split_by_shop/shop_' + str(shop))\n",
    "    print('xxxxxxxxxxxxxxxxxxxxxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f736ed5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_953814/2894162328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_953814/2894162328.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#Extract shop list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0munique_shops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_monthed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shop_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdf_monthed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_no_sale_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_monthed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_shops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_953814/1289288138.py\u001b[0m in \u001b[0;36madd_no_sale_entries\u001b[0;34m(df_func, months, unique_shops)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonths_not_sold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;31m#Create entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mitem_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_item_price\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mitem_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_item_category\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0msold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_953814/1289288138.py\u001b[0m in \u001b[0;36mget_item_price\u001b[0;34m(date, df_func)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprice_list_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprice_list_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice_list_before\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2086\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m         \"\"\"\n\u001b[0;32m-> 2088\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#run notebook\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main executable that governs the execution of rest of notebook. \n",
    "    \"\"\"\n",
    "    #Create main df\n",
    "    sales_path = 'historic_sales_data.csv'\n",
    "    items_path = 'items.csv'\n",
    "    df = create_main_df(sales_path, items_path)\n",
    "    \n",
    "    #Aggregate sales to monthly\n",
    "    df_monthed = construct_monthly_sales_df(df.copy())\n",
    "\n",
    "    #Limit data to 2020 products\n",
    "    date_limit = datetime(2020, 1, 1)\n",
    "    df_monthed = twenty20_products(df_monthed, date_limit)\n",
    "\n",
    "    #Limit data by date\n",
    "    date_limit = datetime(2019, 3, 1)\n",
    "    df_monthed = limit_data_by_date(df_monthed, date_limit)\n",
    "    \n",
    "    #Drop unwanted columns\n",
    "    columns_to_drop = ['year_month', 'day']\n",
    "    df_monthed = drop_columns(df_monthed, columns_to_drop)\n",
    "    \n",
    "    #Add no sale entries\n",
    "    date_start = datetime(2019, 3, 1)\n",
    "    date_end = datetime(2020, 5, 1)\n",
    "    months = pd.date_range(date_start, date_end, freq='MS')\n",
    "    #Set date as index\n",
    "    df_monthed = df_monthed.set_index('date')\n",
    "    #Extract shop list\n",
    "    unique_shops = df_monthed['shop_id'].unique()\n",
    "    df_monthed = add_no_sale_entries(df_monthed, months, unique_shops)\n",
    "    \n",
    "    print('-------------------------------------------')\n",
    "    print('-------------------------------------------')\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
