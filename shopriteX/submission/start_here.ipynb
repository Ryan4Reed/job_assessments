{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63d8d96",
   "metadata": {},
   "source": [
    "# Shoprite X Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a9b4b",
   "metadata": {},
   "source": [
    "### Selected approach\n",
    "\n",
    "During my initial explorations of the problem at hand, I considered many alternative approaches. These included more traditional statistical approaches like ARIMa and Facebooks Prophet model, as well as ML based approaches\n",
    "\n",
    "After some time the nature of the problem and the limited time available, pointed me in the appropriate direction. That is, statistical approaches like ARIMA, as well as the prophet model, rely heavily on the anlyst to provide it with the right kind of data in order to make good predictions. In addition to the requirement that the time series distribution for which a prediction is made has to be stationary (which our data does not satisfy). It also requires the distribution to be modelled to be very specific to the problem at hand. One would essentially need to model the sales of every shop-product combination seperately. Given the effort required to standardise every such distribution, this was infeasable. As such, it was clear that the ml based approach was the way to go.\n",
    "\n",
    "Consequently, I proceeded to create a ml based model (xgboost) for each of the 59 shops in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae91061",
   "metadata": {},
   "source": [
    "### Structure of submission\n",
    "\n",
    "This assessment is divided into the following notebooks:\n",
    "   * Initial_data_exploration.ipynb\n",
    "        * This notebook is dedicated to an initial exploration of the data and is a good place to go from here.\n",
    "    * main_data_preparation.ipynb\n",
    "        * This notebook contains a clear explanation of the details around how we prepare the data for modeling.\n",
    "    * xgboost_daily.ipynb\n",
    "        * This notebook illustrate the result of a model I trained to provide daily forecasts. From the insight gained here, I switched course to forecasting on a monthly level.\n",
    "    * xgboost_monthly.ipynb\n",
    "        * This notebook contains the model that generated the submitted predictions\n",
    "    * format_data_for_submission.ipynb\n",
    "        * This notebook is dedicated to aggregating the predictions made for june for each shop into one csv for submission.\n",
    "    * segmentation_analysis.ipynb\n",
    "        * This notebook contains an incomplete segmentation analysis. Unfortunately, I did not have the time to complete it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f86e5",
   "metadata": {},
   "source": [
    "### Future work\n",
    "\n",
    "There is a considerable amount of future work to be considered here. For one, I was not able to complete the segmentation analysis. Had I more time, I would indeed complete the segmentation analysis and adapt my model according to insights gained. \n",
    "\n",
    "With respect to the xgboost model, one improvement I would like to have implemented was to make the hyperparameter tuning dynamics and shop specific. That is, I completed hyperparameter tuning on a particular shop and utilised those optimal parameters for model training across all shops. It would have been better to have determined the optimal hyperparameters seperate wrt the model dedicated to each shop and have those dynamically feed into the final model trained for that shop. \n",
    "\n",
    "Furthermore, I would have like to investigate why the xgboost model has a select few very high predictions wrt to sales. Are these reasonable, or are there some outliers that I missed that is causing this behaviour?\n",
    "\n",
    "Moving on from the xgboost model, I would have liked to experiment with alternative ml models. In particular a lstm architecture to better exploit the sequential nature of the data. \n",
    "\n",
    "The data provided contains certain products that are sold frequenly and some that are seldomly sold. The problem with the products that are seldomly sold (in terms of modelling) is that the data is zero-saturated. This limits our options in terms of approaches. For products that are commonly sold however, it would be interesting to experiment with statistical based approaches like ARIMA. The advantage of these approaches is that they have the capacity to better exploit the time series nature of the data. They do, however, have very strict requirements for the data, which is why they were not pursued in this assessment.\n",
    "\n",
    "An interesting approach that would likely result in better performance in predicting the sales of product is to train two models instead of one. Have one model trained on whether a item was sold or not on a particular day, and have a second model trained on how many products were sold if the first product predicts a sale. The advantage of this approach is that one could train the second model only on data related to actual sales, thereby reducing the affect of the imballance in the dataset as a result of most days having no sales. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc79b1",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "The predictions for the month of may can be found in a file called june_predictions in the folder title preds_monthly_by_shop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c115f2",
   "metadata": {},
   "source": [
    "In terms of the quality of the results, they were not terrible. I was somewhat suprised in a good way at the models performance. But more work is required. The zero-inflated nature of the data made modelling tricky. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e7b79",
   "metadata": {},
   "source": [
    "Thanks for the opportunity to have completed the assessment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
